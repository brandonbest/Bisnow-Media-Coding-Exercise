QUESTION 3
You could add a clustered index over type and city. The speed of the read queries would go up tremendously, but (even) more disk space is required for this. Justifying the need for that or a different index would depend on what other queries are typically being run on this db. If for example, it is also common to run queries where the 'where' clause involves only type or only city, having two non-clustered indices (one for each of type and city) might be a better solution. Or if a lot of other queries run could involve other columns than type or city in the where clause, then the best solution might be neither of the previous I suggested (would need more information to flush this scenario out). If a lot of the other queries run involve adding data into the db, especially if those occur more often than the query in the question, the value of the clustered index I suggested goes down quite a bit. More context is really needed to make a final decision here.

Regarding alternatives, let's talk about the data involved - it is literally neatly fit into a single, short table. There is no reason for me to believe that a non-traditional RDBMS makes sense here. If the data were unstructured, loosely coupled, better fit to a graph or other non-tabular format - then maybe it would make sense to consider a NoSQL solution.

Now lets' talk about the queries being run - they are all reads. Yet another reason to stick with a traditional RDBMS. They scale perfectly well on reads. It's scaling writes that really gets interesting.

While MySQL is a great, lightweight, open-source DB fit for plenty of things, my thought is that when dealing with this much data (500 million rows) I'd move to SQL Server or Oracle.

QUESTION 2
-PART A-
If you are a good open source application framework like Laravel, you have an interface for session handling and a corresponding Memcache specific implementation (and perhaps other implementations). You then have a configuration in an clear, obvious to spot location, that can be changed to utilize another implementation. Then people contributing to your project can add an implementation for another session handling service to your project without any pain (they add their own implementation of aforementioned interface, and add a configuration option).

If you are a bad open source application framework like CodeIgniter, you do the same as the above except that you have the CodeIgniter core code rigorously verify at run-time that any modules being used for most things is in a specific subfolder within the CodeIgniter directory (ugh). 

-PART B-
PHP (and Java for that matter) only allows for single inheritance. Since some of the classes already extend another class, we can't just add a class (concrete or abstract) that they all inherit from. The way that PHP (and Java) have adapted to this obvious design flaw is with a construct known as a trait. A trait solves the exact issue this problem describes. 

Since we are told that only some of the classes extend another unrelated class, there is almost certainly no way we can redesign the classes that avoids the use of a trait somewhere. Also an interface is not the best bet here because the classes are sharing the methods (ie not implementing their own version of a common method). 

In C++ however, I would probably add another class that all these classes inherit from. Now if only there was more web development being done in this wonderful language.

QUESTION 1
This probably depends on what is meant here by 'customer analytics'. What kind of ways are we going to query the information? How often? How far back of data is relevant? What are we willing to spend? (In addition to the few grand per month committed for SparkPost to send that many emails that is)

The short answer is that all you need to provide SparkPost with is a valid endpoint, from which execution should continue to parse the JSON and store it in any store.

It's hard for me to say what I think would really be best here but I imagine what's most common for this kind of thing is to use Python or Scala and Hadoop. Not that you couldn't use PHP with Hadoop or that you couldn't use PHP and a traditional RDBMS for this problem (and in fact, setting up SparkPost to send and receive emails within a Laravel application is actually a piece of cake, and probably not much more difficult in another PHP MVC framework). It's just more common to work with big, ugly data in other languages and to perform analytics with this much data over Hadoop. 

The fields that strike me as most relevant for customer analytics are campaign_id, rcpt_meta, rcpt_tags, rcpt_type, subject, target_link_name, target_link_url, rcpt_subs. AKA if we are trying to learn about which customers respond to which emails, the information about the what campaign this email is associated with, what link was clicked, what subject attracted the customers attention and demographic data on the customer are what strike me as important.